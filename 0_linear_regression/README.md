## Linear Regression 线性回归

Q1: 线性回归的一般表示形式?

Q2: 如何求解线性回归的参数w/b ?
- 基于均方误差最小化来求解, 也叫最小二乘法(least square method)
- 欧氏距离(Euclidean Distance)
- 最小二乘法就是试图求得一条直线，让样本到直线上的欧氏距离最小; 这个过程叫做: 线性回归模型的最小二乘"参数估计"(parameter estimation).

Q3: 单个属性和多元(多属性)线性回归模型的差异? 在表达形式和求解参数w/b上的

Q4: 从参数表达式求参数的数学方法
- 令表达式对w或b的一阶导数为0，求出w 和 b

Q5: 为什么会有多个满足条件的参数解? 怎么处理 ? 
- 满秩矩阵
- 正则化

Q6: 线性回归 如何过度到 对数线性回归(log-linear regression) ? 在坐标轴上将它们联系起来?

Q7: 将Q6中的过度进行抽象化，得出广义线性模型(generalized linear model), 它的表达式是什么?
- g(·)
- Q6中的g(·) 实际上是 ln(·)

Q8: 广义线性模型的参数估计如何实现？
- 加权最小二乘法
- 极大似然估计
